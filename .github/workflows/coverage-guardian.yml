name: Coverage Guardian Enforcement

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.12'
  COVERAGE_THRESHOLD: 100

jobs:
  security-critical-coverage:
    runs-on: ubuntu-latest
    name: Security Critical Files Coverage
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi
        pip install pytest coverage pytest-cov
    
    - name: Run Coverage Guardian
      run: |
        chmod +x scripts/ci_coverage_check.sh
        scripts/ci_coverage_check.sh
      env:
        COVERAGE_THRESHOLD: ${{ env.COVERAGE_THRESHOLD }}
    
    - name: Upload coverage reports to Codecov
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage.xml
        fail_ci_if_error: true
        verbose: true
        flags: security-critical
    
    - name: Upload HTML coverage report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: coverage-html-report
        path: htmlcov/
        retention-days: 30
    
    - name: Upload coverage artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: coverage-artifacts
        path: coverage_artifacts/
        retention-days: 30
    
    - name: Verify 100% Coverage
      run: |
        coverage report --fail-under=${{ env.COVERAGE_THRESHOLD }}
        echo "✅ 100% Coverage requirement verified"
    
    - name: Security Files Coverage Check
      run: |
        echo "🔒 Validating security-critical files coverage..."
        SECURITY_FILES="makepin.py recoverpin.py helpers.py words.py"
        for file in $SECURITY_FILES; do
          if [ -f "$file" ]; then
            file_coverage=$(coverage report --include="$file" | tail -1 | awk '{print $4}' | sed 's/%//')
            if [ "$file_coverage" != "100" ]; then
              echo "❌ SECURITY RISK: $file has $file_coverage% coverage (MUST be 100%)"
              exit 1
            fi
            echo "✅ Security file $file: 100% coverage"
          fi
        done
    
    - name: Comment PR with coverage
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const path = 'coverage.json';
          
          if (fs.existsSync(path)) {
            const coverage = JSON.parse(fs.readFileSync(path, 'utf8'));
            const totalCoverage = coverage.totals.percent_covered_display;
            
            const comment = `## 🛡️ Coverage Guardian Report
            
            **Total Coverage: ${totalCoverage}%**
            
            ✅ **GUARDIAN STATUS: ${totalCoverage === '100' ? 'APPROVED' : 'BLOCKED'}**
            
            ### Security-Critical Files Status
            - makepin.py: 100% ✅
            - recoverpin.py: 100% ✅  
            - helpers.py: 100% ✅
            - words.py: 100% ✅
            
            ### Reports Generated
            - HTML Report: Available in artifacts
            - XML Report: Uploaded to Codecov
            - JSON Report: Available in artifacts
            
            *This comment was generated by the Coverage Guardian CI/CD system.*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }

  complete-test-suite:
    runs-on: ubuntu-latest
    name: Complete Test Suite with Guardian
    needs: security-critical-coverage
    
    strategy:
      matrix:
        python-version: ['3.11', '3.12']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi
        pip install pytest coverage pytest-cov jq
    
    - name: Run Complete Test Suite
      run: |
        chmod +x scripts/run_complete_test_suite.sh
        scripts/run_complete_test_suite.sh
    
    - name: Upload test artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-artifacts-py${{ matrix.python-version }}
        path: test_artifacts/
        retention-days: 30
    
    - name: Generate test summary
      if: always()
      run: |
        if [ -f "test_artifacts/test_summary.json" ]; then
          echo "📊 Test Summary:"
          cat test_artifacts/test_summary.json | jq .
        fi

  performance-validation:
    runs-on: ubuntu-latest
    name: Performance Impact Assessment
    needs: complete-test-suite
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi
        pip install pytest coverage pytest-benchmark
    
    - name: Performance benchmark with coverage overhead
      run: |
        echo "🚀 Running performance tests with coverage overhead..."
        time coverage run --source=. -m pytest tests/ -v
        echo "✅ Performance validation completed"
    
    - name: Memory usage analysis
      run: |
        echo "💾 Analyzing memory usage during coverage collection..."
        /usr/bin/time -v coverage run --source=. -m pytest tests/ 2>&1 | grep -E "(Maximum resident set size|User time|System time)"

  deployment-readiness:
    runs-on: ubuntu-latest
    name: Deployment Readiness Check
    needs: [security-critical-coverage, complete-test-suite, performance-validation]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi
        pip install pytest coverage
    
    - name: Final Guardian Validation
      run: |
        echo "🛡️ Final Guardian validation for deployment readiness..."
        python scripts/guardian_enforcer.py --threshold ${{ env.COVERAGE_THRESHOLD }}
        echo "✅ Guardian has approved deployment"
    
    - name: Generate deployment report
      run: |
        cat > deployment_report.json << EOF
        {
          "timestamp": "$(date -Iseconds)",
          "commit_sha": "${{ github.sha }}",
          "branch": "${{ github.ref_name }}",
          "coverage_status": "100%",
          "guardian_status": "APPROVED",
          "security_validation": "PASSED",
          "deployment_ready": true,
          "artifacts_generated": [
            "coverage_html", "coverage_xml", "coverage_json", "test_reports"
          ]
        }
        EOF
        
        echo "📋 Deployment Report:"
        cat deployment_report.json | jq .
    
    - name: Upload deployment report
      uses: actions/upload-artifact@v3
      with:
        name: deployment-report
        path: deployment_report.json
        retention-days: 90